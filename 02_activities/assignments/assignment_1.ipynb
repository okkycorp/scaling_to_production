{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with parquet files\n",
    "\n",
    "## Objective\n",
    "\n",
    "+ In this assignment, we will use the data downloaded with the module `data_manager` to create features.\n",
    "\n",
    "(11 pts total)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "+ This notebook assumes that price data is available to you in the environment variable `PRICE_DATA`. If you have not done so, then execute the notebook `production_2_data_engineering.ipynb` to create this data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Load the environment variables using dotenv. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n",
      "cannot find .env file\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv \n",
    "%reload_ext dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "dask.config.set({'dataframe.query-planning': True})\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Load the environment variable `PRICE_DATA`.\n",
    "+ Use [glob](https://docs.python.org/3/library/glob.html) to find the path of all parquet files in the directory `PRICE_DATA`.\n",
    "\n",
    "(1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date       Open       High        Low      Close  Adj Close  \\\n",
      "ticker                                                                     \n",
      "A      2000-01-03  56.330471  56.464592  48.193848  51.502148  43.532219   \n",
      "A      2000-01-04  48.730328  49.266811  46.316166  47.567955  40.206844   \n",
      "A      2000-01-05  47.389126  47.567955  43.141991  44.617310  37.712799   \n",
      "A      2000-01-06  44.080830  44.349072  41.577251  42.918453  36.276852   \n",
      "A      2000-01-07  42.247852  47.165592  42.203148  46.494991  39.299923   \n",
      "\n",
      "         Volume       sector                       subsector  year  \n",
      "ticker                                                              \n",
      "A       4674353  Health Care  Life Sciences Tools & Services  2000  \n",
      "A       4765083  Health Care  Life Sciences Tools & Services  2000  \n",
      "A       5758642  Health Care  Life Sciences Tools & Services  2000  \n",
      "A       2534434  Health Care  Life Sciences Tools & Services  2000  \n",
      "A       2819626  Health Care  Life Sciences Tools & Services  2000  \n",
      "Columns in the DataFrame: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'sector',\n",
      "       'subsector', 'year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import dask\n",
    "dask.config.set({'dataframe.query-planning': True})\n",
    "import dask.dataframe as dd\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the PRICE_DATA environment variable\n",
    "price_data_path = os.getenv('PRICE_DATA')\n",
    "\n",
    "\n",
    "# Use glob to find the path of all parquet files in the directory PRICE_DATA, including nested subdirectories\n",
    "parquet_files = glob(os.path.join(price_data_path, '**', '*.parquet'), recursive=True)\n",
    "\n",
    "\n",
    "# Filter out any directories from the list of parquet files\n",
    "parquet_files = [file for file in parquet_files if os.path.isfile(file)]\n",
    "\n",
    "\n",
    "# Load all the parquet files into a Dask DataFrame\n",
    "dask_df = dd.read_parquet(parquet_files, engine='pyarrow')\n",
    "\n",
    "# Display the first few rows and the columns of the DataFrame to verify the structure and data\n",
    "print(dask_df.head())\n",
    "print(\"Columns in the DataFrame:\", dask_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each ticker and using Dask, do the following:\n",
    "\n",
    "+ Add lags for variables Close and Adj_Close.\n",
    "+ Add returns based on Adjusted Close:\n",
    "    \n",
    "    - `returns`: (Adj Close / Adj Close_lag) - 1\n",
    "\n",
    "+ Add the following range: \n",
    "\n",
    "    - `hi_lo_range`: this is the day's High minus Low.\n",
    "\n",
    "+ Assign the result to `dd_feat`.\n",
    "\n",
    "(4 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the parquet files into a Dask DataFrame\n",
    "dask_df = dd.read_parquet(parquet_files, engine='pyarrow')\n",
    "\n",
    "# Define the function to add features\n",
    "def add_features(df):\n",
    "    df = df.sort_index()\n",
    "    df['Close_lag'] = df['Close'].shift(1)\n",
    "    df['Adj_Close_lag'] = df['Adj Close'].shift(1)\n",
    "    df['returns'] = (df['Adj Close'] / df['Adj_Close_lag']) - 1\n",
    "    df['hi_lo_range'] = df['High'] - df['Low']\n",
    "    return df\n",
    "\n",
    "# Create a sample DataFrame to define metadata\n",
    "sample_df = pd.DataFrame({\n",
    "    'Date': pd.to_datetime([]),\n",
    "    'Open': pd.Series([], dtype='float64'),\n",
    "    'High': pd.Series([], dtype='float64'),\n",
    "    'Low': pd.Series([], dtype='float64'),\n",
    "    'Close': pd.Series([], dtype='float64'),\n",
    "    'Adj Close': pd.Series([], dtype='float64'),\n",
    "    'Volume': pd.Series([], dtype='int64'),\n",
    "    'sector': pd.Series([], dtype='object'),\n",
    "    'subsector': pd.Series([], dtype='object'),\n",
    "    'year': pd.Series([], dtype='int64'),\n",
    "    'Close_lag': pd.Series([], dtype='float64'),\n",
    "    'Adj_Close_lag': pd.Series([], dtype='float64'),\n",
    "    'returns': pd.Series([], dtype='float64'),\n",
    "    'hi_lo_range': pd.Series([], dtype='float64'),\n",
    "})\n",
    "\n",
    "# Apply the feature addition function using map_partitions with accurate metadata\n",
    "dd_feat = dask_df.map_partitions(lambda df: df.groupby('ticker').apply(add_features), meta=sample_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Convert the Dask data frame to a pandas data frame. \n",
    "+ Add a rolling average return calculation with a window of 10 days.\n",
    "+ *Tip*: Consider using `.rolling(10).mean()`.\n",
    "\n",
    "(3 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Date       Open       High        Low      Close  \\\n",
      "ticker ticker                                                          \n",
      "A      A      2000-01-03  56.330471  56.464592  48.193848  51.502148   \n",
      "       A      2000-01-04  48.730328  49.266811  46.316166  47.567955   \n",
      "       A      2000-01-05  47.389126  47.567955  43.141991  44.617310   \n",
      "       A      2000-01-06  44.080830  44.349072  41.577251  42.918453   \n",
      "       A      2000-01-07  42.247852  47.165592  42.203148  46.494991   \n",
      "\n",
      "               Adj Close   Volume       sector  \\\n",
      "ticker ticker                                    \n",
      "A      A       43.532219  4674353  Health Care   \n",
      "       A       40.206844  4765083  Health Care   \n",
      "       A       37.712799  5758642  Health Care   \n",
      "       A       36.276852  2534434  Health Care   \n",
      "       A       39.299923  2819626  Health Care   \n",
      "\n",
      "                                    subsector  year  Close_lag  Adj_Close_lag  \\\n",
      "ticker ticker                                                                   \n",
      "A      A       Life Sciences Tools & Services  2000        NaN            NaN   \n",
      "       A       Life Sciences Tools & Services  2000  51.502148      43.532219   \n",
      "       A       Life Sciences Tools & Services  2000  47.567955      40.206844   \n",
      "       A       Life Sciences Tools & Services  2000  44.617310      37.712799   \n",
      "       A       Life Sciences Tools & Services  2000  42.918453      36.276852   \n",
      "\n",
      "                returns  hi_lo_range  \n",
      "ticker ticker                         \n",
      "A      A            NaN     8.270744  \n",
      "       A      -0.076389     2.950645  \n",
      "       A      -0.062030     4.425964  \n",
      "       A      -0.038076     2.771820  \n",
      "       A       0.083333     4.962444  \n",
      "                    Date       Open       High        Low      Close  \\\n",
      "ticker ticker                                                          \n",
      "A      A      2000-01-03  56.330471  56.464592  48.193848  51.502148   \n",
      "       A      2000-01-04  48.730328  49.266811  46.316166  47.567955   \n",
      "       A      2000-01-05  47.389126  47.567955  43.141991  44.617310   \n",
      "       A      2000-01-06  44.080830  44.349072  41.577251  42.918453   \n",
      "       A      2000-01-07  42.247852  47.165592  42.203148  46.494991   \n",
      "\n",
      "               Adj Close   Volume       sector  \\\n",
      "ticker ticker                                    \n",
      "A      A       43.532219  4674353  Health Care   \n",
      "       A       40.206844  4765083  Health Care   \n",
      "       A       37.712799  5758642  Health Care   \n",
      "       A       36.276852  2534434  Health Care   \n",
      "       A       39.299923  2819626  Health Care   \n",
      "\n",
      "                                    subsector  year  Close_lag  Adj_Close_lag  \\\n",
      "ticker ticker                                                                   \n",
      "A      A       Life Sciences Tools & Services  2000        NaN            NaN   \n",
      "       A       Life Sciences Tools & Services  2000  51.502148      43.532219   \n",
      "       A       Life Sciences Tools & Services  2000  47.567955      40.206844   \n",
      "       A       Life Sciences Tools & Services  2000  44.617310      37.712799   \n",
      "       A       Life Sciences Tools & Services  2000  42.918453      36.276852   \n",
      "\n",
      "                returns  hi_lo_range  rolling_avg_return  \n",
      "ticker ticker                                             \n",
      "A      A            NaN     8.270744                 NaN  \n",
      "       A      -0.076389     2.950645                 NaN  \n",
      "       A      -0.062030     4.425964                 NaN  \n",
      "       A      -0.038076     2.771820                 NaN  \n",
      "       A       0.083333     4.962444                 NaN  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows to verify the features were added correctly\n",
    "print(dd_feat.head())\n",
    "\n",
    "# Convert the Dask DataFrame to a pandas DataFrame\n",
    "pandas_df = dd_feat.compute()\n",
    "\n",
    "# Add a rolling average return calculation with a window of 10 days\n",
    "pandas_df['rolling_avg_return'] = pandas_df['returns'].rolling(10).mean()\n",
    "\n",
    "# Display the first few rows to verify the rolling average return was added correctly\n",
    "print(pandas_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please comment:\n",
    "\n",
    "+ Was it necessary to convert to pandas to calculate the moving average return?\n",
    "+ Would it have been better to do it in Dask? Why?\n",
    "\n",
    "(1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria\n",
    "\n",
    "|Criteria|Complete|Incomplete|\n",
    "|---------------------|----|----|\n",
    "|Calculations         |Calculations were done correctly.|Calculations were not done correctly.|\n",
    "|Explanation of answer|Answer was concise and explained the learner's reasoning in depth.|Answer was not concise and did not explained the learner's reasoning in depth.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "🚨 **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** 🚨 for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-1`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-3-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
